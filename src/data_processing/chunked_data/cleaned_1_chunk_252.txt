self.lrn2 = nn.LocalResponseNorm(128)
# The 7 th and 8 th convolutional layers have dropout in training
self.dropout = nn.Dropout(p=0.5)
self.apply(self.weight_init)
def forward(self, x):
# Inception module
x_3x3 = self.conv_3x3(x)
x_1x1 = self.conv_1x1(x)
x = torch.cat([x_3x3, x_1x1], dim=1)
self.fc1 = nn.Linear(self.features_size, 1024)
self.fc2 = nn.Linear(1024, n_classes)
self.apply(self.weight_init)
def _get_final_flattened_size(self):
with torch.no_grad():
x = torch.zeros((1, 1, self.input_channels,
self.patch_size, self.patch_size))
x = self.conv1(x)
b = x.size(0)
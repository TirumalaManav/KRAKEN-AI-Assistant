kwargs.setdefault('dropout', False))
lr = kwargs.setdefault('learning_rate', 0.0001)
optimizer = optim.Adam(model.parameters(), lr=lr)
criterion = nn.CrossEntropyLoss(weight=kwargs['weights'])
kwargs.setdefault('epoch', 100)
kwargs.setdefault('batch_size', 100)
elif name == 'hamida':
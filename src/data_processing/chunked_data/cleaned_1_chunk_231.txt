init.zeros_(m.bias)
def _get_final_flattened_size(self):
with torch.no_grad():
x = torch.zeros(1, 1, self.input_channels)
x = self.pool(self.conv(x))
return x.numel()
def __init__(self, input_channels, n_classes, kernel_size=None, pool_size=None):
super(HuEtAl, self).__init__()